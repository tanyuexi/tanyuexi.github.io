---
layout: post
title:  "Neural Networks for Machine Learning - UT [Course]"
author: Yuexi Tan
date:   2016-03-18 16:00:00 +0800
tags:  Machine-Learning
---

<img src="{{ "/images/20160318-NNforML-240x135.png" | prepend: site.baseurl }}">

<fieldset>
  <legend id="outline">Outline</legend>
  <a href="#course-information">Course information</a><br>
  <a href="#lecture-1-introduction">Lecture 1: Introduction</a><br>
  <a href="#lecture-2-the-perceptron-learning-procedure">Lecture 2: The Perceptron learning procedure</a><br>
  <a href="#lecture-3-the-backpropagation-learning-proccedure">Lecture 3: The backpropagation learning proccedure</a><br>
  <a href="#lecture-4-learning-feature-vectors-for-words">Lecture 4: Learning feature vectors for words</a><br>
  <a href="#lecture-5-object-recognition-with-neural-nets">Lecture 5: Object recognition with neural nets</a><br>
  <a href="#lecture-6-optimization-how-to-make-the-learning-go-faster">Lecture 6: Optimization: How to make the learning go faster</a><br>
  <a href="#lecture-7-recurrent-neural-networks">Lecture 7: Recurrent neural networks</a><br>
  <a href="#lecture-8-more-recurrent-neural-networks">Lecture 8: More recurrent neural networks</a><br>
  <a href="#lecture-9-ways-to-make-neural-networks-generalize-better">Lecture 9: Ways to make neural networks generalize better</a><br>
  <a href="#lecture-10-combining-multiple-neural-networks-to-improve-generalization">Lecture 10: Combining multiple neural networks to improve generalization</a><br><a href="#lecture-11-hopfield-nets-and-boltzmann-machines">Lecture 11: Hopfield nets and Boltzmann machines</a><br>
  <a href="#lecture-12-restricted-boltzmann-machines-rbms">Lecture 12: Restricted Boltzmann machines (RBMs)</a><br>
  <a href="#lecture-13-stacking-rbms-to-make-deep-belief-nets">Lecture 13: Stacking RBMs to make Deep Belief Nets</a><br>
  <a href="#lecture-14-deep-neural-nets-with-generative-pre-training">Lecture 14: Deep neural nets with generative pre-training</a><br>
  <a href="#lecture-15-modeling-hierarchical-structure-with-neural-nets">Lecture 15: Modeling hierarchical structure with neural nets</a><br>
  <a href="#lecture-16-recent-applications-of-deep-neural-nets">Lecture 16: Recent applications of deep neural nets</a><br>
</fieldset>

## Course information

[This course](https://class.coursera.org/neuralnets-2012-001) was given by Geoffrey Hinton, University of Toronto. It is really a good course which connects all the terms that I used to saw here and there together, and gives intuitive explanations for abstract concepts. Not to mention that the professor currently is well recognized as the top researcher on machine learning. **Highly recommended.** 

------

## Lecture 1: Introduction

### 1.1 我们为什么需要机器学习？

大家都知道，只要你能把一个任务编写成代码，就能让电脑替你完成这个任务。然而<mark>对于某些任务，你很难把它写成具体的代码</mark>。什么样的任务呢？

+ 我们能够轻松完成这个任务，但说不清自己的大脑是怎么实现的；即使可以，描述出来也是相当复杂的。例如：辨认不同人的面孔，手写数字识别（见[Fig1.1-1](#Fig1.1-1)）
+ 没有明显规则、需要通过蛛丝马迹来推测的任务。例如：银行监控信用卡诈骗事件
+ 情况在随时改变的任务。例如：预测股票涨跌

<img src="{{ "/images/20160318-MNIST-300x200.png" | prepend: site.baseurl }}" id="Fig1.1-1">

*Fig1.1-1 MNIST task.*

于是，我们的思维需要更上一层楼。与其直接写执行该任务的程序，不如写另外一种程序：它能根据我们提供的输入来进行自我调整，直到符合任务要求。如果输入有改变，那么这种程序也会跟着变。这种程序的样子长得和经典程序不同，它的核心不是一行行结构精巧的语句，而是由训练产生的大量数字。毕竟，<mark>现在计算和数据的成本远远比雇程序猿写代码的成本低</mark>。这就是“机器学习（Machine Learning）”。机器学习的典型任务有：

+ 模式识别：真实场景下的物体、面孔身份或表情、语音
+ 异常监测：信用卡交易异常、核电站传感器读数异常
+ 预测：股市或外汇走势、某个消费者可能会喜欢什么样的电影

而在众多的机器学习方法中，（人工）神经网络（Neural Network）近年来的表现十分惊艳：用神经网络方法完成的任务的准确度，相较于其他方法，有质的飞跃。

### 1.2 什么是神经网络？

为什么要关心在生命体内，神经如何进行计算？

+ 为了理解真实的脑子是如何工作的。因为生物脑很大、很复杂，而且如果向里面扎入检测仪器，脑子就会死，所以需要用电脑进行仿真实验
+ 因为生物脑的计算是并行、可变的，这与串行计算的电脑很不相同，所以研究生物脑可以为计算机科学家们带来启发。如果从这一点出发，那么我们应该关注大脑擅长而电脑不擅长的问题（如：视觉），而不应该关注电脑擅长而大脑不擅长的问题（如：加减乘除等运算）
+ 受到生物脑启发而开发出来的算法，有的虽然并不完全符合生物运行机制，但确实能够解决实际问题，也是很有意义的

<mark>人工神经网络受到了生物脑的以下几点启发</mark>：

+ 神经元相互连接。每个神经元可以接受来自其他神经元的输入，也可以向其他神经元输出信号
+ 神经元之间的连接有不同的强度，可以用一个实数来表示。而且连接有两种功能：兴奋性和抑制性，分别用正负号+/-来表示
+ 神经元之间的连接强度在学习过程中可以被改变
+ 脑内神经元的数量巨大，大脑皮层各区的潜能很相似，从而能够完成灵活多样的任务

例如 [Fig1.2-1](#Fig1.2-1)，仅仅三个神经元就可以实现 AND（与）的计算。

<img src="{{ "/images/20160318-NnAnd-640x360.png" | prepend: site.baseurl }}" id="Fig1.2-1">

*Fig1.2-1 Neurons for AND computation. From Course "[Machine Learning](https://www.coursera.org/learn/machine-learning)" by Andrew Ng*

### 1.3 一些简单的神经元模型

要为一个东西建模，我们就必须将其理想化，因为：

+ 只有将复杂但不重要的大量细节去掉，我们才能理解主要的原理
+ 简单的模型便于我们将数学工具用在上面、利用相似系统的已有研究成果
+ 一旦我们理解了主要原理，把它复杂化、令其更贴近真实系统就变得很容易了
+ 即使模型明显与真实系统不符，理解它也是很有价值的

#### <span id="linear-neuron">Linear Neurons</span>

每个神经元的输出是其输入的加权和（[Fig1.3-1](#Fig1.3-1)），即：输出 = ( 各输入 x 连接强度 ) 之和。这个模型很简单，但应用很受局限。

<img src="{{ "/images/20160318-LinearNeuron-400x164.png" | prepend: site.baseurl }}" id="Fig1.3-1">

*Fig1.3-1 Linear Neurons.*

#### <span id="binary-threshold-neuron">Binary Threshold Neurons</span>

在 [Linear Neurons](#linear-neuron) 的基础上，加入阈值机制。即，只有当输入的加权和超过阈值时，神经元才被激活并输出 1，否则输出为 0（[Fig1.3-2](#Fig1.3-2)）。式子中表示阈值的是 b（bias，“误差”），即 -b = 阈值。

<img src="{{ "/images/20160318-BinaryThresholdNeuron-400x192.png" | prepend: site.baseurl }}" id="Fig1.3-2">

*Fig1.3-2 Binary Threshold Neurons.*

#### <span>Rectified Linear Neurons (Linear Threshold Neurons)</span>

结合了 [Linear Neurons](#linear-neuron) 和 [Binary Threshold Neurons](#binary-threshold-neuron)。即，只有当输入的加权和低于阈值时，神经元输出为 0，否则输出等于输入的线性和（[Fig1.3-3](#Fig1.3-3)）。

<img src="{{ "/images/20160318-RLN-400x118.png" | prepend: site.baseurl }}" id="Fig1.3-3">

*Fig1.3-3 Rectified Linear Neurons, or Linear Threshold Neurons.*

#### <span id="sigmoid-neuron">Sigmoid Neurons</span>

在 [Binary Threshold Neurons](#binary-threshold-neuron) 的基础上稍有调整。每个神经元的输出不再是简单的分段函数，而是其输入的加权和的 Sigmoid 函数（[Fig1.3-4](#Fig1.3-4)）。在这里，<mark>使用 Sigmoid Neurons 有以下几个好处</mark>：

+ Sigmoid 函数是有界函数，其上下界分别为 1 和 0
+ Sigmoid 函数处处可导，为后续的学习步骤提供了数学上的便利

<img src="{{ "/images/20160318-SigmoidNeuron-300x234.png" | prepend: site.baseurl }}" id="Fig1.3-4">

*Fig1.3-4 Sigmoid Neurons.*

#### <span>Stochastic Binary Neurons</span>

在 [Sigmoid Neurons](#sigmoid-neuron) 的基础上，<mark>将 Sigmoid 函数视为“输出为 1 ”的概率分布。这样一来，神经元的输出就不完全依赖于输入，而是具有一定的随机性</mark>（[Fig1.3-5](#Fig1.3-5)）。

<img src="{{ "/images/20160318-SBN-400x305.png" | prepend: site.baseurl }}" id="Fig1.3-5">

*Fig1.3-5 Stochastic Binary Neurons.*

### 1.4 三种机器学习类型

+ Supervised Learning：根据输入预测输出。进而还可分为两种：
   - Regression：输出是连续实数。例如，根据身高预测体重
   - Classification：输出是离散类型。例如，根据肤色预测种族
+ Reinforcement Learning：选择令回报最大化的行动。例如，机器人动作控制
+ Unsupervised Learning：发现输入的内在特征，通常为了便于后续的监督学习或增强学习。例如，提取相同主题的文章的特征

[[Go to outline](#outline)]

------

## Lecture 2: The Perceptron learning procedure

### 2.1 几种主要的神经网络架构

+ <mark>Feed-forward Neural Networks（FNN）</mark> ([Fig2.1-1A](#Fig2.1-1))
   - 实际应用中最常见的类型
   - 第一层神经元是输入层，最后一层神经元是输出层。每个神经元的输出无法回到自身
   - 它对输入样本进行了一系列变换（transformation），从而改变了样本之间的相似度
   - 上一层神经元的活动是下一层神经元的非线性函数
   - 如果它的隐藏层多于一层，则被称为“深度”神经网络
+ <mark>Recurrent Neural Networks（RNN）</mark> ([Fig2.1-1B](#Fig2.1-1))
   - 被认为是适用于序列数据的自然模型
   - 神经元之间的连接是有向循环。神经元的输出可以回到自身。相当于很深的 FNN，只不过每两层神经元之间的连接强度总是一样的
   - 这种结构使其具有复杂的动态变化，能够长时间“记住”信息，但是难以训练参数
   - 更接近生命体机制
+ <mark>Symmetrically Connected Networks</mark>
   - 与 RNN 相似，只不过神经元连接是对称的。即，连接是双向的，且连接强度相等
   - Hopfield 等发现，对称的网络比 RNN 分析起来更容易
   - 但是由于它们遵循一个能量方程，所以它们能做的事情很有限
   - 没有隐藏神经元的对称网络被称为“Hopfield Nets”
   - 具有隐藏神经元的对称网络被称为“Boltzmann Machines”
      + 它比 Hopfield Nets 更加强大
      + 但是弱于 RNN
      + 有一个优美的学习算法


<img src="{{ "/images/20160318-FnRnn-400x352.png" | prepend: site.baseurl }}" id="Fig2.1-1">

*Fig2.1-1 Feed-forward Neural Networks (A) and Recurrent Neural Networks (B).*

### 2.2 Perceptrons：第一代神经网络

Perceptron 的方法在1960年代早期因 Frank Rosenblatt 的工作变得广为人知的。然而到了1969年，Minsky 和 Papert 出版了一本名为“ Perceptrons ”的书，并于其中分析了 Perceptrons 能做什么、不能做什么，使得许多人错误地认为 Perceptrons 的局限性对于所有的神经网络都是成立的。从此神经网络模型遭遇了长达十几年的寒冬。直到1980年代，物理学家 Hopfield 发表的关于人工神经网络的文章引起了巨大反响，再加上计算机硬件技术的发展、其他机器学习方法遇到瓶颈，神经网络才又火起来。无论如何，Perceptrons 现在仍是被广泛使用的方法，特别是对于特征数量庞大的任务。

Perceptrons 的结构如下图：

<img src="{{ "/images/20160318-Perceptron-300x251.png" | prepend: site.baseurl }}" id="Fig2.2-1">

*Fig2.2-1 The standard Perceptron architecture.*

简单来说，对于一个“判断输入样本是类别 0 还是类别 1 ”的任务，<mark>Perceptrons 的工作步骤</mark>是：

+ 人工提取输入向量的特征
+ 学习，以决定每一个特征的权重 w。最后的输出为一个值。此学习过程将于后文阐述
+ 如果这个值大于某个阈值，那么输入样本为类别 1，否则为类别 0

看到这里，你可能已经想起 Lecture 1 提到的 [Binary Threshold Neurons](#binary-threshold-neuron)：当输入的加权和超过阈值时，输出为 1，否则为 0；阈值用 b 来表示。为了计算的方便，我们将 b 看做一个特殊神经元和上层神经元的连接强度，这个特殊神经元的输出总是为 1，而阈值变成了0（[Fig2.2-2](#Fig2.2-2)）。

<img src="{{ "/images/20160318-BiasAsWeight-150x155.png" | prepend: site.baseurl }}" id="Fig2.2-2">

*Fig2.2-2 Bias as weight.*

<mark>如何训练 Perceptrons，得到合适的权重（神经元连接强度）呢？</mark>

+ 初始化权重，例如 [5,5,5]
+ 输入训练样本，例如 [2,2,2]
   - 如果输出正确，则保持权重不变
   - 如果输出错误，且输出为 0，则权重向量**加上**输入向量，得到新权重 [7,7,7]
   - 如果输出错误，且输出为 1，则权重向量**减去**输入向量，得到新权重 [3,3,3]
+ 重复上一步骤，依次输入其他训练样本，更新权重

这个训练方式能**保证**找到一套权重，以正确分类所有的训练样本，<mark>只要这套权重存在（重要前提）</mark>。为什么？请看下文：

### 2.3 从几何角度来理解 Perceptrons

为了便于说明，先让大家熟悉几个概念。学过线性代数的同学可能理解起来更轻松。

**权重空间（weight space）**是指数目确定的权重，其具体取值的所有可能性。每增加一个权重就增加了一维。例如，一个只有两个输入神经元的 Perceptrons 有两个权重。这两个权重的取值范围就构成了一个二维的权重空间，其中包括 [0,0]，[1,2]，[3.3,4.25]，[-9,1000] 等等无穷个点。权重空间中的一点（向量），表示所有权重的一套具体值，例如 [4,3] 表示第一个权重取 4，第二个权重取 3。

由于在 Perceptrons 里，输入向量的维数和权重向量的维数相等，所以我们还有一个和权重空间维数相等的**样本空间（sample space）**。同样的，样本空间内的一个点（向量），表示了一个具体样本，例如 [2,2]。

我们希望将输入向量作为限制条件，将无穷大的权重空间缩小至特定范围，从而这个小范围内的任意一点就都是我们想找的权重了。现在，让我们把权重空间和样本空间重叠在一起，也就是说，把权重向量和输入向量置于同一个空间考虑（[Fig2.3-1](#Fig2.3-1)）。这样，我们就把问题转化为：<mark>当与输入向量是什么关系时，权重向量是一个好的向量？</mark>

<img src="{{ "/images/20160318-WISpace-300x229.png" | prepend: site.baseurl }}" id="Fig2.3-1">

*Fig2.3-1 What is a good weight vector.*

现在，请回想一下 Perseptrons 的输出是怎么计算得到的：输入的加权和，即，输入向量和权重向量的内积。若内积为负，则为类别 0，否则为类别 1。而线性代数的知识告诉我们，当两个向量同向时，内积为正；当两个向量互为反向时，内积为负。<mark>所以我们要找的权重向量，必须与所有类别 1 的样本向量同向，而与所有类别 0 的样本向量反向</mark>。

由此可见，Perceptrons 的训练过程的本质是，对于每一个已知类别的训练样本：

+ 若分类正确，则保持权重向量不变
+ 若将类别 1 错判为类别 0，则将权重向量往正方向修正
+ 若将类别 0 错判为类别 1，则将权重向量往负方向修正

但是有没有可能，满足所有条件的权重向量根本不存在呢？如图 [Fig2.3-2](#Fig2.3-2)，实心点是同一类别，空心点是另一类别。所以，<mark>Perceptrons 局限1：当样本是线性不可分时，不存在能够将所有训练样本正确分类的权重向量</mark>。一个典型例子是，将内容不同但是亮度相同的两张图像分别进行平移，生成两组样本。Perceptions 无法将这些样本正确分类，而模式识别的最重要功能就是识别平移图像。

<img src="{{ "/images/20160318-PerceptronLimitation-300x237.png" | prepend: site.baseurl }}" id="Fig2.3-2">

*Fig2.3-2 When such weight vector does not exist.*

除此之外，<mark>Perceptrons 局限2：需要人工构造特征，作为输入向量</mark>。如果能够知道特征，那么 Perceptrons 就是很强大的工具。

<mark>Perceptrons 局限3：因为没有隐藏层，输入-输出的对应关系很少，应用受限</mark>。如果仅仅单纯地增加几层线性神经元，那么效果不大，因为它们仍然是线性关系。所以我们需要加入多层隐藏神经元，且神经元之间的关系应是非线性的。然而这样一来，训练网络（学习权重）就变难得多了。下一讲，你会知道这样的网络如何进行学习。

[[Go to outline](#outline)]

------

## Lecture 3: The backpropagation learning proccedure

### 3.1 Linear Neurons 的权重学习：The Delta-rule

为什么 Perceptrons 的学习过程不能套用到含有隐藏层的非线性网络？因为 Perceptrons 的成功建立在一个前提之上：两个好的权重向量之和，是一个更好的权重向量。然而这个前提无法推广到更复杂的网络。怎么办呢？我们需要换个思路。

回忆 Perceptrons 的学习过程：其本质是不断调整权重向量，使其更接近目标权重向量（对于每一个训练样本，其目标权重向量是已知的）。然而，现在目标权重向量变成未知的了。不过目标输出仍然是已知的。所以，与其让权重向量接近目标权重向量，还不如<mark>让实际输出接近目标输出</mark>来得更容易些，即，观察实际与目标的误差的大小。

容易想到，我们似乎可以用数学分析的方法将各权重解出来：对于线性神经元，根据“输出 = 输入的加权和”以及“误差 = 实际和目标之差的平方”，我们可以为每一个训练样本写出一个方程，然后找出令误差最小的方程组的解。问题解决了，但是实际上我们并不这样做。原因是：

+ 从科学的角度来看，真实的神经元肯定不是通过解方程组来学习权重的
+ 从工程的角度来看，我们需要一种能够推广到多层、非线性网络的方法：<mark>迭代法。虽然效率更低，却易于推广</mark>

举例说明一下迭代法。假设你在餐厅点了 2 份鱼、5 份薯条和 3 份番茄酱。你并不知道这些食物的单价，只知道收银员总共收了你 850 的钱（[Fig3.1-1](#Fig3.1-1)）。那么如何推测每样食物多少钱呢？

<img src="{{ "/images/20160318-IterReal-400x254.png" | prepend: site.baseurl }}" id="Fig3.1-1">

*Fig3.1-1 The true weights used by the cashier.*

首先，瞎猜个价格（比如，全为单价 50）。根据这个瞎猜的价格，总价应为 500，与实际相差 350（即，残差）。回忆 Perceptrons 的学习方法：当输出与目标不符时，根据输入向量来改变权重向量。在这里也是类似的，只不过要将输入向量稍作改变后，再调整权重向量。这种学习方法叫做 <mark>Delta-rule</mark>。如图 [Fig3.1-2](#Fig3.1-2) 。

<img src="{{ "/images/20160318-IterDeltaRule-600x251.png" | prepend: site.baseurl }}" id="Fig3.1-2">

*Fig3.1-2 Delta-rule with arbitrary initial weights.*

对于迭代法的表现，人们会关心两个问题：

+ 迭代法能够保证找到正确的权重向量吗？一方面，完美的解可能不存在；另一方面，如果学习速率足够小的话，我们可以接近最优解
+ 权重的收敛速度如何？如果输入的某两项总是高度相关，那么收敛将会非常慢

另外，Delta-rule 分为两种：

+ 批量（batch）学习。根据所有的训练样本计算总误差，整个学习过程仅更新一次权重
+ 实时（online）学习。对每个训练样本都计算一个误差并更新权重，更新权重的次数与训练样本数相等

由前文可见，<mark>Delta-rule 与 Perceptrons 有相似性。那么它们之间的区别是什么呢？</mark>

+ Perceptrons 的权重调整量 = 输入向量。且只有输出错误时，权重才会被调整
+ Delta-rule 的权重调整量 = 输入向量 x 残差 x 学习速率（learning rate）。而选择学习速率是一件很恼人的事，原因是：

### 3.2 Linear Neurons 的误差曲面

稍加回忆可知，[Sigmoid Neurons](#sigmoid-neuron) 的本质，是在 Linear Neurons 的基础上加入了阈值机制和 S 形的输出函数。所以在理解 Sigmoid Neurons 的学习方法之前，我们可以从更简单的 Linear Neurons 着手。

对于特定的任务，权重是有最优解的，即，取值越偏离最优解，误差越大。<mark>这个误差曲面的水平切面是椭圆形的，而纵向切面是碗状的，而我们的目标是到达碗底</mark>（[Fig3.2-1](#Fig3.2-1)）。

<img src="{{ "/images/20160318-ErrorSurface-400x116.png" | prepend: site.baseurl }}" id="Fig3.2-1">

*Fig3.2-1 The error surface is bowl-shape.*

<mark>批量学习能够使权重沿着下降最快的路径进行改变</mark>（[Fig3.2-2](#Fig3.2-2)）。

<img src="{{ "/images/20160318-BatchLearning-200x128.png" | prepend: site.baseurl }}" id="Fig3.2-2">

*Fig3.2-2 Batch learning does steepest descent on the error surface.*

<mark>实时学习则令权重在这条路径周围呈 Z 字形下降</mark>（[Fig3.2-3](#Fig3.2-3)）。

<img src="{{ "/images/20160318-OnlineLearning-300x167.png" | prepend: site.baseurl }}" id="Fig3.2-3">

*Fig3.2-3 Online learning zig-zags around the direction of steepest descent.*

那么，<mark>什么情况下的权重学习会很慢呢？答案是：当误差曲面的水平切面是一个很长的椭圆</mark>、最陡路径的切线几乎与其总体走势垂直时。因为学习速率决定了每走一步的大小，所以在这种情况下，如果学习速率太大，权重就会一直在路径两边剧烈震荡、难以收敛；如果学习速率太小，需要的迭代次数太多，收敛依然很慢（[Fig3.2-4](#Fig3.2-4)）。

<img src="{{ "/images/20160318-ElongateErrorSurface-200x229.png" | prepend: site.baseurl }}" id="Fig3.2-4">

*Fig3.2-4 Elongate error surfaces make slow learning.*

至此，我们已经了解线性神经元是如何进行权重学习的了。那么，如何让非线性神经元 Sigmoid Neurons 进行权重学习呢？

### 3.3 权重学习：从 Linear Neurons 推广至 Sigmoid Neurons

已知在 Linear Neurons 的学习过程中，权重调整量 = 输入向量 x 残差 x 学习速率。表示如下：

<img src="{{ "/images/20160318-DeltaRuleLN-600x252.png" | prepend: site.baseurl }}" id="Fig3.3-1">

*Fig3.3-1 Deriving the delta-rule in Linear Neurons.*

在 Sigmoid Neurons 的学习过程中，如果我们把误差对权重求偏导，可以得到与 Linear Neurons 相似的式子。推导过程如下：

<img src="{{ "/images/20160318-DeltaRuleSN-600x725.png" | prepend: site.baseurl }}" id="Fig3.3-2">

*Fig3.3-2 Deriving the delta-rule in Sigmoid Neurons.*

也就是说，<mark>只要将 Linear Neurons 的权重调整量中的“学习速率”替换成 y(1-y)，即是 Sigmoid Neurons 的权重调整量</mark>。推广完毕。

### 3.4 The Backpropagation Algorithm

前面我们已经知道如何调整单个权重，那么如何训练整个网络呢？自然地，你可能会想到：随机改变权重的值，如果能令输出更接近目标，则保存这个改变，直到神经网络能正确工作。实际上，这确实是 Reinforcement Learning 的一种形式。但是，这种方法非常低效，而且当学习进行到最后时，大的扰动反而令结果更糟。

所以我们的思维需要更上一层楼。由于“权重”对输出的作用不如“隐藏神经元活动”直接，所以<mark>与其扰动权重，不如直接扰动隐藏神经元活动状态，在得到理想的隐藏神经元活动后，再反推相应的权重取值</mark>。

然而，由于<mark>随机扰动效率很低</mark>，所以我们需要一个更聪明的策略。请回想一下 Delta-rule 的原理：根据输入向量和输出误差来调整权重。同理，我们何不据此来调整隐藏神经元的活动呢？即，隐藏神经元活动的调整量～输入向量和误差对活动的偏导。想法很好，然而唯一的问题是：<mark>输出向量和输入向量中间隔着多层隐藏神经元</mark>，我们无法直接套用 Delta-rule。当大家一筹莫展时，<mark>The Backpropagation Algorithm</mark> 的出现拯救了世界！

通过把玩数学魔法，有人发现了 Sigmoid Neurons 的神奇特性：当上层更接近输出、下层更接近输入时，<mark>通过上一层神经元活动的调整量可以计算下一层神经元活动的调整量，通过神经元活动可以计算权重</mark>。如图 [Fig3.4-1](#Fig3.4-1)，以下值可被依次求出：

+ 上层神经元活动调整量 *dE/dy<sub>j</sub>*
+ 下层神经元活动调整量 *dE/dy<sub>i</sub>*
+ 下层神经元活动 *y<sub>i</sub>*
+ 上层与下层之间权重的调整量 *dE/dw<sub>ij</sub>*

<img src="{{ "/images/20160318-Backpropagation-600x270.png" | prepend: site.baseurl }}" id="Fig3.4-1">

*Fig3.4-1 The backpropagation algorithm. See how dE/dy is backpropagating.*

核心的理论难关已被攻破！那么还需考虑的事情仅剩：

+ <mark>优化问题：如何充分使用训练样本？</mark>
   - 多久更新一次权重？
      + 实时（online）：一个训练样本更新一次
      + 全批量（full batch）：所有样本处理完后才更新一次
      + 小批量（mini-batch）：每次抽取部分样本并更新一次
   - 多大的调整幅度？
      + Use a fixed learning rate
      + Adapt the global learning rate
      + Adapt the learning rate on each connection separately
      + Don’t use steepest descent
+ <mark>推广问题：如何保证训练好的网络在新样本上也能正确工作？</mark>
   - 采样错误导致学习到的特征不具代表性
   - 网络太复杂导致过拟合。可能的解决方法：
      + Weight-decay
      + Weight-sharing
      + Early stopping
      + Model averaging
      + Bayesian fitting of neural nets 
      + Dropout
      + Generative pre-training

啊！好不容易搞懂了一个，怎么又来俩！要不然……先轻松一下，看看神经网络怎么解决实际问题：学习语义、物体识别。等到了 [Lecture 6](#lecture-6-optimization-how-to-make-the-learning-go-faster) 和 [Lecture 9](#lecture-9-ways-to-make-neural-networks-generalize-better) 再来纠结这两个问题吧？

[[Go to outline](#outline)]

------

## Lecture 4: Learning feature vectors for words

### 4.1 “认亲戚”任务

现在有两个家谱（[Fig4.1-1](#Fig4.1-1)）。神经网络的任务是：推测两个人的关系，即使在训练样本中并没有这两个人的直接关系。比如，我们用“Colin has-father James, Colin has-mother Victoria”等信息训练神经网络。训练完毕后，当我们输入“Who is James‘ wife”时，它能够输出“Victoria”。

<img src="{{ "/images/20160318-FamilyTrees-500x256.png" | prepend: site.baseurl }}" id="Fig4.1-1">

*Fig4.1-1 Two family trees. Family A is from England. Family B is from Italy.*

经过训练，神经网络自己学会了几个特征（[Fig4.1-2](#Fig4.1-2)），其中容易理解的有：特征 4 表示国籍，特征 5 表示第几代。

<img src="{{ "/images/20160318-FamilyTreeFeatures-500x560.png" | prepend: site.baseurl }}" id="Fig4.1-2">

*Fig4.1-2 Learned features.*

于是你发现：哟嚯！这神经网络知道什么是“老婆”，它能理解概念了！

### 4.2 打个岔：认知科学

“认亲戚”任务可以引发我们对于“什么是概念”的探讨。长久以来有两个假说：

+ 特征论：概念是一系列语义特征
+ 结构论：概念的存在依赖于它与其他概念的关系

实际情况可能是二者的结合。因为我们能理解的概念中既有明确的、独立的“定义”，也有说不清的、与别的东西联系在一起的“常识”。

### 4.3 “语音识别”任务：神经概率语言模型

另一类任务是“语音识别”。它的的难点在于：<mark>在真实环境中，会出现一个词听上去和几个词都很像的情况，这时就需要根据上下文来推测正确的词</mark>。为了解决这个问题，以前的人们一直使用一种叫“三词（trigram）”的方法：统计在大量文本资料中，当相邻两个词为 a 和 b 时，接下来第三个词为 c 的频率，进而计算相对概率。然而这个方法有缺陷：三词组合的可能性数量实在过于庞大，而且里面大部分为零；另外，即使某个组合的出现概率的统计结果为零，事实上却仍有可能出现。仔细考虑后可以发现，“三词法”没有利用两个很重要的信息：语义、语法。通过上面的“认亲戚”的例子，我们已经见识了神经网络在“理解概念”上的潜力，所以自然想到用神经网络尝试解决这个问题。

在之前的神经网络的例子中，由于输出函数是 Sigmoid，所以输出值为一个接近于 0 或 1 的数。而在这个任务中，每个输出对应着一个词，输出值为“第三个词为该词”的概率，所有词的概率之和应等于 1，这是 Sigmoid 输出函数无法满足的。所以我们需要改用 <mark>Softmax 输出函数：输出和为 1，其输出对输入的偏导与 Sigmoid 函数的偏导一样</mark>（[Fig4.3-1](#Fig4.3-1)）。

<img src="{{ "/images/20160318-Softmax-200x251.png" | prepend: site.baseurl }}" id="Fig4.3-1">

*Fig4.3-1 The Softmax output function.*

但是仍然存在一个问题：当目标输出为 1，而实际输出接近于 0 时，Softmax 的偏导将非常小，误差修正的速度将非常慢。这个问题的根源在于，我们使用了误差平方作为代价函数。如果将代价函数换成“交叉熵（cross-entropy）”，则其偏导为 *y<sub>i</sub> - t<sub>i</sub>*，<mark>补偿了 Softmax 偏导在两端的趋于平缓的问题，所以 Softmax 经常与 cross-entropy 配合使用</mark>（[Fig4.3-2](#Fig4.3-2)）。

<img src="{{ "/images/20160318-CrossEntropy-300x240.png" | prepend: site.baseurl }}" id="Fig4.3-2">

*Fig4.3-2 Cross-entropy.*

交叉熵是信息论里的概念，我觉得用在这里其实也没啥特严肃的道理，只是因为它能够提供一些数学上的便利罢了。没学过信息论的人估计无论如何都不会想到用交叉熵来解决这个问题。所以要想在学科交叉处创新，“先有问题再学知识”固然是效率最高的办法，但是有的问题需要“先有知识”才能联想到解决方案。

然而问题总是不绝。假设有100k个词，当我们把 Softmax 用在输出层时，最上层的每个隐藏神经元就会有100k个输出权重，这是很恐怖的数量级。那么如何解决<mark>大量输出的问题</mark>呢？

（此讲后面一堆没看懂，等看懂了再更新）

讲完了“语音识别”任务，下面来看看“物体识别”任务。

[[Go to outline](#outline)]

------

## Lecture 5: Object recognition with neural nets

### 5.1 物体识别为什么难？

+ 分割问题：真实场景中许多东西都混杂在一起。一方面需要判断哪个区域属于同一个物体，另一方面物体可能因为某些部位被遮挡而不完整
+ 光照问题：物体的明暗、色调会受光照影响
+ 功能可见性：“同一个物体”通常是以功能是否相同来定义的，而非外形是否相似
+ 数据组织错误：比如将病人的“年龄”误录入在“体重”一栏
+ 畸变问题：物体的平面图像可能进行非仿射变换。而仿射变换的物体识别（即视觉不变性）曾经是难题，直到最近才被解决。详见：

### 5.2 如何达到“视觉不变”？

视觉不变是指，即使对图案进行平移、缩放、翻转、旋转和错切等仿射变换，大脑仍然能够判断“这是同一个物体”。这是计算机感知技术中最主要的困难，长久以来没有公认的良策。由于生物脑太擅长这个任务，所以许多人认为这并没有什么了不起。为了解决这个问题，人们开发了多种方法：

+ 利用稳定（即经过变换后仍然不变）的特征。但是要避免误将其他物体的特征包括进来
+ 用暴力尝试法在物体周围画一个框，然后进行变换。但是只有先知道物体的样子才能画框。这是一个“鸡生蛋蛋生鸡”的问题
+ 利用有明确姿势的、有层级关系的部件相对于摄像头的位置。将于课程稍后解释
+ 对同一特征运用多个检测单元。这叫“<mark> Convolutional Neural Networks（CNN）</mark>”，是现在神经网络应用的主流方法。详见下文

### 5.3 Convolutional Neural Networks

对一个可能发生了平移的图案，我们可以将其特征检测单元复制好几个，置于不同位置上，使得无论图案平移到哪里，至少有一个单元能够检测出来（[Fig5.3-1](#Fig5.3-1)）。当然，除了“位置”，我们也可以在“大小”和“方向”的层面复制检测单元，但这很难，而且代价很高。另外，我们还可以对同一个图案同时检测多个特征。总之，<mark>从本质上看，CNN 只不过比基本神经网络在寻找目标权重的过程中多了一些限制条件</mark>。

<img src="{{ "/images/20160318-CNN-200x280.png" | prepend: site.baseurl }}" id="Fig5.3-1">

*Fig5.3-1 Convolutional Neural Networks.*

事实上，只要将 Backpropagation Algorithm 稍加修改，便能实现 CNN：按照原方法计算每个权重的调整量后，令处于不同位置上的检测单元的实际调整量相等，即，对应权重的调整量之和。这样一来，只要某一处的检测单元能够满足条件，则所有位置上的检测单元都应是满足条件的（[Fig5.3-2](#Fig5.3-2)）。

<img src="{{ "/images/20160318-CNNweights-300x292.png" | prepend: site.baseurl }}" id="Fig5.3-2">

*Fig5.3-2 Constraints in Convolutional Neural Networks.*

一个著名的成功例子是纽约大学的 [Yann LeCun](http://yann.lecun.com) 于 1989 年开发的 LeNet，当时被用于美国 10% 的支票号码识别（[Fig5.3-3](#Fig5.3-3)）。

<img src="{{ "/images/20160318-LeNetTranslate-320x200.gif" | prepend: site.baseurl }}" id="Fig5.3-3">
<img src="{{ "/images/20160318-LeNetScale-320x200.gif" | prepend: site.baseurl }}">

*Fig5.3-3 LeNet using Convolutional Neural Networks.*

通过 LeNet 可知，<mark>关于任务的先验知识可以指导我们设计出更好的网络</mark>，如：权重的限制条件、网络连通程度、神经元激活函数等。虽然这比人工设计特征更好地保留了神经网络方法的优势，但是仍令网络或多或少地倾向于某类任务。另一种利用先验知识的方法是，<mark>生成更大的训练集</mark>，比如将训练集中的图片进行仿射变换后作为额外的样本，用于训练神经网络。虽然这样很累人，也导致训练时间变长，但是能让深层神经网络自动发现一些可能连人类都无法完全理解的巧妙方法。

如果将识别任务，从平面的黑白的手写数字，扩展到立体的彩色的真实物体，那么我们会遇到新的困难：

+ 待区分的类别增加了百倍（1000 vs 10）
+ 像素点变多了百倍（256 x 256 彩色 vs 28 x 28 灰度）
+ 照片是三维物体向二维平面的投影
+ 需要将照片中的物体分割出来
+ 同一张照片里有多个物体

在 ILSVRC-2012 图像分类竞赛中，多伦多大学的 Alex Krizhevsky 在 LeNet 的启发下，通过利用深层 CNN、GPU 和许多其他技巧，将错误率降低至 16.4%，超越第二名多达十个百分点。

[[Go to outline](#outline)]

------

## Lecture 6: Optimization: How to make the learning go faster

### 6.1 小批量学习的梯度下降

回忆 [3.2 Linear Neurons 的误差曲面](#linear-neurons-)，其水平切面是椭圆形的。如果这个椭圆形很长且我们使用的是全批量学习方法，则：

+ 当梯度很大时，下降方向并不指向目标，偏偏此时权重的调整量很大，引起误差震荡
+ 当梯度很小时，下降方向虽然指向目标，但是此时权重的调整量很小，误差难以收敛

所以像“全批量学习”这样试图一步到位的方法会遇到不少问题。那么，我们能不能保守一些，每走一步都重新评估一下现状与目标方向，分几步到达目标？其实前文提到的“实时学习”就是这种思路的极端例子：总步数与训练样本数一样多，频繁更新权重。但是这样计算量太大、计算时间很长。一个折衷的解决方案是<mark>“小批量学习”：将训练样本分为几组，每组仅计算一次权重调整量，且这几组的计算可以并行</mark>。需要注意的是，分组要保持样本分布均匀，不应出现某组富集某类样本的情况。总之，对于样本量很大、网络很大的训练，小批量学习几乎总是你的最佳选择。

### 6.2 一堆关于小批量学习的技巧

由前文可知，权重的调整量过大或过小都不好。而在神经网络的训练过程中，人为干预权重调整量的唯一途径是改变学习速率。所以，选择一个合适的学习速率是成败关键。

选择学习速率的最直观原则是：<mark>若误差出现震荡，则减小学习速率；若误差下降得太慢，则增大学习速率</mark>。这个过程可以用程序自动化。但是要注意，应使用独立的数据集来测量误差，即，训练集与测试集要分开。另外，通常在训练进行至尾声时都应减小学习速率，因为这样能够去除随机浮动。但是，如果过早地减小学习速率，那么虽然误差会在短期内快速下降，但是随后的学习会非常缓慢，因为快速减小的仅仅是随机误差，其余误差是网络不优带来的（[Fig6.2-1](#Fig6.2-1)）。

<img src="{{ "/images/20160318-LearnRateTooSoon-300x219.png" | prepend: site.baseurl }}" id="Fig6.2-1">

*Fig6.2-1 Do not turning down the learning rate too soon.*

考虑到如果两个隐藏神经元的输入和输出完全一致，则无论如何训练，它俩都无法互相区分开。所以，我们可以<mark>用随机的小数值来初始化权重</mark>。多小才好呢？想象一下，如果一个隐藏神经元有许多输出，那么输入即使发生微小变化，也会极大地影响结果。所以，我们可以令初始权重大致正比于“输出数的平方根”。同样的，学习速率也可以这么缩放。

另外，我们还可以<mark>通过对输入进行平移和缩放，来避免误差曲面的水平切面呈长椭圆形</mark>（[Fig6.2-2](#Fig6.2-2)）。能达到相同效果的更强力的方法是，<mark>对输入向量进行去相关化、降维</mark>，比如主成分分析。

<img src="{{ "/images/20160318-ShiftScaleInput-400x785.png" | prepend: site.baseurl }}" id="Fig6.2-2">

*Fig6.2-2 Shift and scale the input to avoid elongated, elliptical error surfaces.*

在训练深层网络的过程中，常见的、<mark>容易被误以为是局部最优的“平台期假象”</mark>有：

+ 学习速率太大，令误差居高不下
+ 当输出值的意义不是值本身，而是“输出为 1 的概率”时，神经网络通常要花很长时间根据输入来自我改进（？这里没看懂）

四种<mark>令小批量学习更快的方法</mark>，其中前三种将于下文详细介绍：

+ “动量法”调整权重。即，调整的不是权重本身，而是权重改变的快慢
+ 让每个权重拥有独立的、可变的学习速率
+ rmsprop：令学习速率根据历史梯度进行缩放
+ 一种利用了曲度信息的很酷炫的方法（此讲不介绍）

### 6.3 动量法

动量法就像是放一个球在误差曲面上，让其自由滚动。在刚开始，球会沿着最陡路经下降。不久后，球就会偏离最陡路经。这样，在梯度方向一致时，球会滚得越来越快；在梯度多变的时候，球的震荡会比梯度的震荡小（[Fig6.3-1](#Fig6.3-1)）。权重调整量 = 球的速度。

<img src="{{ "/images/20160318-Momentum-200x157.png" | prepend: site.baseurl }}" id="Fig6.3-1">

*Fig6.3-1 Momentum method.*

动量法的实现也很简单。<mark>根据上一次的实际权重调整量和本次的理论权重调整量，计算出本次的实际权重调整量</mark>，如图 [Fig6.3-2](#Fig6.3-2)。

<img src="{{ "/images/20160318-MomentumWeights-800x324.png" | prepend: site.baseurl }}" id="Fig6.3-2">

*Fig6.3-2 The equations of the momentum method.*

标准的动量法是，先计算该点的梯度方向，然后向该方向跨一步。而<mark>一种更好的 Nesterov 方法是，先顺着上次跨步的方向跨一步，然后根据新地点的梯度进行修正</mark>。

### 6.4 让每个权重拥有独立的、可变的学习速率

为什么让所有的权重使用统一的学习速率不好呢？一、不同层通常有不同数量级的梯度；二、对于有很多输出的神经元，同时改变很多权重会导致“矫枉过正”。

如何让每个权重拥有独立的、可变的学习速率呢？如图 [Fig6.4-1](#Fig6.4-1)，设权重调整量为梯度、学习速率、增益的乘积。首先将增益初始化为 1。如果上次调整与本次调整方向（即符号）相同，则稍微增大增益，否则稍微减小增益。这样，一旦发生震荡，增益就会迅速减小，阻止震荡。

<img src="{{ "/images/20160318-SeparatedWeights-300x293.png" | prepend: site.baseurl }}" id="Fig6.4-1">

*Fig6.4-1 One way to determine the individual learning rates.*

### 6.5 rmsprop：梯度除以近期平均梯度

rmsprop 是 rprop 的“小批量学习”版本。rprop 方法：因为无法为所有的权重取统一的学习速率，所以在全批量学习中仅使用梯度的符号，令所有权重以相同的数量级进行调整。与刚刚介绍的方法 [Fig6.4-1](#Fig6.4-1) 不同的是，增大权重调整量的操作是乘，而非加。rprop 无法应用在小批量学习上，因为多次相乘的权重调整量会变得十分巨大。于是就有了能够用于小批量学习的 rmsprop。

（后面没看懂）

[[Go to outline](#outline)]

------

## Lecture 7: Recurrent neural networks

### 7.1 为序列建模：概览

在许多机器学习任务中，输入和输出是两种完全不同的数据，比如，输入语音，输出词语。然而还有另一种任务，需要通过已输入的数据来推测接下来的数据，即关于序列的任务。比如，根据图像的其他部分，推测缺失部分的像素内容。这种任务处于无监督学习和监督学习的模糊地带。

说到这里，你可能会想起前文提到的 [4.3 “语音识别”任务：神经概率语言模型](#section-7)。虽然这个模型可以根据未知词语的上下文进行推测，但是上下文的词语个数是有限且固定的，所以它本质上仍是一个“没有记忆”的模型。其他功能类似的模型有“线性动力系统”和“隐马尔科夫模型”等（[Fig7.1-1](#Fig7.1-1)）。

<img src="{{ "/images/20160318-LDSandHMM-600x392.png" | prepend: site.baseurl }}" id="Fig7.1-1">

*Fig7.1-1 Linear Dynamical Systems (A) and Hidden Markov Models (B).*

像隐马尔科夫这样的模型的局限是：变量一多，隐状态就多，隐状态之间的转换概率数量更多。相较之下，RNN 更具优势：它能储存许多信息，且神经元之间是非线性关系。只要有足够的神经元和时间，它能够计算出任何能够被计算的东西。但这种强大的能力也令其难以训练。

### 7.2 用 Backpropagation 训练 RNN

回忆，[5.3 Convolutional Neural Networks](#convolutional-neural-networks) 的学习其实就是在寻找权重的过程中增加了限制条件：常规地计算权重调整量后，令不同位置的权重的调整量为二者之和，从而达到同时调整相应权重的效果。同理，如果我们将 RNN 看成一种特殊的 FNN（[Fig7.2-1](#Fig7.2-1)）：

<img src="{{ "/images/20160318-RNN-600x302.png" | prepend: site.baseurl }}" id="Fig7.2-1">

*Fig7.2-1 Recurrent Neural Networks as a special group of Feed-forward Neural Networks.*

则很容易理解 <mark>RNN 的训练过程：常规地计算权重调整量后，令权重的调整量等于各时刻计算出的调整量之和</mark>。但是有一个令人讨厌的问题：我们要给所有隐藏神经元和输出神经元设初始值。解决办法是：把初始值当作权重一样去训练。下图是一个简单例子：二进制加法计算器（[Fig7.2-2](#Fig7.2-2)）。

<img src="{{ "/images/20160318-RnnBinAdd-600x427.png" | prepend: site.baseurl }}" id="Fig7.2-2">

*Fig7.2-2 A finite state automaton for binary addition (A, not RNN!) and its desired output (B).*

如果用 RNN 来实现二进制加法，则需要 2 个输入神经元，3 个完全连接的隐藏神经元，以及 1 个输出神经元。

<mark>为什么说 RNN 难以训练？因为在 Backpropagation 的过程中，前后时刻的权重是线性关系的，如果序列很长，则权重要么消失要么爆炸</mark>。为了解决这个问题，人们开发了四种有效的 RNN 学习方法：

+ **Hessian Free Optimization**: 当曲度很小时，也能捕捉到梯度
+ **Echo State Networks**: 仅学习隐藏神经元与输出神经元之间的权重，而用一种精心设计的方法来初始化其他东西，使得隐藏层能够发生震荡
+ **Good initialization with momentum**: 用 Echo State Networks 初始化输入，然后用动量法学习所有权重
+ **Long Short Term Memory（LSTM）**: 改变 RNN 的结构，使其能够长期保留信息。详见下文：

### 7.3 Long term short term memory

Hochreiter 和 Schmidhuber 于 1997 开发的 <mark>LSTM 解决了 RNN 难以记住长序列的问题。他们设计了一种“记忆细胞”，由三个门控制：写入门（将信息写入记忆细胞）、保留门（让记忆细胞持续保留信息）、读出门（将记忆细胞中的信息输出）。若门值为 1，则该功能被激活；若门值为 0，则该功能被抑制</mark>（[Fig7.3-1](#Fig7.3-1)）。

<img src="{{ "/images/20160318-LSTM-300x298.png" | prepend: site.baseurl }}" id="Fig7.3-1">

*Fig7.3-1 Long Short Term Memory cell with three gates.*

很容易想到应用 LSTM 的任务是“手写字母识别”（[Fig7.3-2](#Fig7.3-2)）。

<video src="{{ "/images/20160318-LstmHandwriting.mp4" | prepend: site.baseurl }}" autoplay loop id="Fig7.3-2">
  <p>Sorry! Your browser does not support the video tag.</p>
</video>

*Fig7.3-2 A demonstration of online handwriting recognition by an RNN with Long Short Term Memory.*

[[Go to outline](#outline)]

------

## Lecture 8: More recurrent neural networks

[[Go to outline](#outline)]

------

## Lecture 9: Ways to make neural networks generalize better

[[Go to outline](#outline)]

------

## Lecture 10: Combining multiple neural networks to improve generalization

[[Go to outline](#outline)]

------

## Lecture 11: Hopfield nets and Boltzmann machines

[[Go to outline](#outline)]

------

## Lecture 12: Restricted Boltzmann machines (RBMs)

[[Go to outline](#outline)]

------

## Lecture 13: Stacking RBMs to make Deep Belief Nets

[[Go to outline](#outline)]

------

## Lecture 14: Deep neural nets with generative pre-training

[[Go to outline](#outline)]

------

## Lecture 15: Modeling hierarchical structure with neural nets

[[Go to outline](#outline)]

------

## Lecture 16: Recent applications of deep neural nets

[[Go to outline](#outline)]
